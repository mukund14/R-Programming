Customer Potential Classification
Introduction: In every business, it is important to know what would be a good investment and what would be risky. Red Hat had posted its customer behavior data on the Kaggle website. They wanted to find who would be a good target for future benefit. Essentially, they wanted to determine whether the customer would be worth investing in the future. We have to come up with a model which will help in this prediction and help them understand whether these customers depending on their behavior would be a good fit. 
Approach:
We have 3 tables for this particular problem: Training, Testing and People Table.
Let’s import these datasets into R with the read command.
Since we want to work with a large dataset, we will use the h2o library since it can work very effectively with large datasets and has been gaining increasing popularity.
> library(h2o)
> library(data.table)
// For faster read operations, we use fread operation with data.table.
> train <- fread('act_train.csv')
Read 2197291 rows and 15 (of 15) columns from 0.131 GB file in 00:00:04
> test <- fread('act_test.csv')
> people<-fread("people.csv")

// if we look at the file for people, we will see:
> str(people)
Classes ‘data.table’ and 'data.frame':	189118 obs. of  41 variables:
 $ people_id: chr  "ppl_100" "ppl_100002" "ppl_100003" "ppl_100004" ...
 $ char_1   : chr  "type 2" "type 2" "type 2" "type 2" ...
 $ group_1  : chr  "group 17304" "group 8688" "group 33592" "group 22593" ...
 $ char_2   : chr  "type 2" "type 3" "type 3" "type 3" ...
 $ date     : chr  "2021-06-29" "2021-01-06" "2022-06-10" "2022-07-20" ...
 $ char_3   : chr  "type 5" "type 28" "type 4" "type 40" ...
 $ char_4   : chr  "type 5" "type 9" "type 8" "type 25" ...
 $ char_5   : chr  "type 5" "type 5" "type 5" "type 9" ...
 $ char_6   : chr  "type 3" "type 3" "type 2" "type 4" ...
 $ char_7   : chr  "type 11" "type 11" "type 5" "type 16" ...
 $ char_8   : chr  "type 2" "type 2" "type 2" "type 2" ...
 $ char_9   : chr  "type 2" "type 4" "type 2" "type 2" ...
 $ char_10  : logi  TRUE FALSE TRUE TRUE FALSE TRUE ...
 $ char_11  : logi  FALSE FALSE TRUE TRUE FALSE TRUE ...
 $ char_12  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_13  : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...
 $ char_14  : logi  TRUE FALSE TRUE TRUE FALSE TRUE ...
 $ char_15  : logi  FALSE FALSE TRUE FALSE FALSE TRUE ...
 $ char_16  : logi  TRUE FALSE FALSE TRUE FALSE TRUE ...
 $ char_17  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_18  : logi  FALSE FALSE FALSE TRUE FALSE FALSE ...
 $ char_19  : logi  FALSE FALSE TRUE TRUE FALSE TRUE ...
 $ char_20  : logi  FALSE FALSE FALSE TRUE FALSE TRUE ...
 $ char_21  : logi  TRUE FALSE TRUE TRUE FALSE TRUE ...
 $ char_22  : logi  FALSE FALSE TRUE TRUE FALSE TRUE ...
 $ char_23  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_24  : logi  FALSE FALSE TRUE FALSE FALSE TRUE ...
 $ char_25  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_26  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_27  : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...
 $ char_28  : logi  TRUE FALSE TRUE TRUE FALSE TRUE ...
 $ char_29  : logi  FALSE FALSE FALSE TRUE FALSE FALSE ...
 $ char_30  : logi  TRUE TRUE FALSE TRUE FALSE TRUE ...
 $ char_31  : logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
 $ char_32  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_33  : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...
 $ char_34  : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...
 $ char_35  : logi  TRUE TRUE FALSE TRUE TRUE TRUE ...
 $ char_36  : logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
 $ char_37  : logi  FALSE FALSE TRUE TRUE FALSE TRUE ...
 $ char_38  : int  36 76 99 76 84 90 2 91 84 76 ...

Char 1- 38 . the different characteristics exhibited by people over time.

// If we look at these two files of activity which is, act_train and act_test now, 
> str(train)// This command will give variables list
Classes ‘data.table’ and 'data.frame':	2197291 obs. of  16 variables:
 $ people_id        : chr  "ppl_100" "ppl_100" "ppl_100" "ppl_100" ...
 $ activity_id      : chr  "act2_1734928" "act2_2434093" "act2_3404049" "act2_3651215" ...
 $ date             : chr  "2023-08-26" "2022-09-27" "2022-09-27" "2023-08-04" ...
 $ activity_category: chr  "type 4" "type 2" "type 2" "type 2" ...
 $ char_1           : chr  "" "" "" "" ...
 $ char_2           : chr  "" "" "" "" ...
 $ char_3           : chr  "" "" "" "" ...
 $ char_4           : chr  "" "" "" "" ...
 $ char_5           : chr  "" "" "" "" ...
 $ char_6           : chr  "" "" "" "" ...
 $ char_7           : chr  "" "" "" "" ...
 $ char_8           : chr  "" "" "" "" ...
 $ char_9           : chr  "" "" "" "" ...
 $ char_10          : chr  "type 76" "type 1" "type 1" "type 1" ...
 $ outcome          : int  0 0 0 0 0 0 1 1 1 1 ...
 $ train            : num  1 1 1 1 1 1 1 1 1 1 ...

People_id – id of the customer 
Activity_id- unique activity id of the customer
Char ‘1-10’ -activity characteristics that each person has performed over time. 
Each row in this activity file represents a unique activity performed by a person on a certain date.

// train variable in the train dataframe is assigned 1 and in the test dataframe is assigned 0 to help our prediction. The outcome in the test dataframe is what we will predict and hence we assign it -1.
> train$train<-  1
> test$outcome<-   -1
> test$train<-   0
// Now, Let’s make one table out of the tables of train and test by using the rbind command.
> act_Data<-rbind(train,test) 
 
// Performing a join operation to perform a join between the two dataframes act_Data and people, we join them by ‘people_id’ column and assign them an alias as ‘.act’ for act_Data and ‘.ppl’ for people.
And assigning this to a new dataframe
> merged_data<-merge(act_Data,people,by='people_id',suffixes = c('.act','.peopl'))
// We want to use H2O library to perform our model training. So, we have to send it to the H2o server. For this purpose, we will have to structure our dataframe in a tabular format and zip it. So, we use the write.table command. We will make it a CSV file which is how we had our dataset originally. So, the separator will be ‘,’. 2 separate tables will be created. One will have the values where customer potential is a good one (1) and other where it isn’t (0).
> write.table(merged_data[merged_data$train==1,], gzfile('./h2Otrain.csv.gz'),quote=F,sep=',',row.names=F)
> write.table(merged_data[merged_data$train==0,], gzfile('./h2Otest.csv.gz'),quote=F,sep=',',row.names=F)

// Let’s start the H20 server with one thread on our local machine with init method.
> h2o.init(nthreads = -1)
 Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         14 hours 38 minutes 
    H2O cluster version:        3.8.3.3 
    H2O cluster name:           H2O_started_from_R_mukun_lxc845 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   1.44 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  4 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    R Version:                  R version 3.3.2 (2016-10-31) 

// The tables have been written and the H2O Server has been started. Now, let’s upload the files to the server.
> Trainh2O <- h2o.uploadFile('./h2Otrain.csv.gz', destination_frame='Cust_potential_train')
> Testh2O <- h2o.uploadFile('./h2Otest.csv.gz', destination_frame='Cust_potential_test')
// Performing feature selection and choosing the relevant features
> Feature_selection <- names(Trainh2O) // will get you the names of the Training model ‘Trainh2O’
> Feature_selection <- Feature_selection[! Feature_selection %in% c('people_id','outcome','train','activity_id')]

// the above command will do the feature selection. We are removing 4 columns in this ‘people_id’, ‘outcome’, ‘train’, ’activity_id’ which will not help in the model prediction. ‘outcome’ will aid in the prediction and it is a target variable which is why we remove it from the model selection.
# train logistic regression model, use family=’gaussian’ to get score 91% 
> drf <- h2o.glm(x=Feature_selection, y='outcome', training_frame = Trainh2O, family='gaussian')
  |====================================================================================| 100%
# train gradient boosting model, use distribution='auto' to get score 92%   
> drf <- h2o.gbm(x=Feature_selection, y='outcome', training_frame = Trainh2O, distribution = "AUTO",ntrees = 100,learn_rate = 1,max_depth = 5)
  |====================================================================================| 100%
# train gradient boosting model, use distribution='auto' to get score 92%  
> sub <- data.frame(activity_id = as.vector(Testh2O$activity_id), outcome = as.vector(predict(drf,Testh2O)))
  |====================================================================================| 100%
> write.table(sub, './finalop.csv',quote=F,sep=',',row.names=F)


// Let’s make the prediction with this model on the test data.

> sub <- data.frame(activity_id = as.vector(Testh2O$activity_id), outcome = as.vector(predict(drf,Testh2O)))
  |====================================================================================| 100%

# create output for making submission
> write.table(sub, './finalop.csv',quote=F,sep=',',row.names=F)

// This is our final output submission file. 

Conclusion:
So, by using their behavior data over time we can determine whether a customer would be a good investment in the future. 
Our logistic regression model gave us an accuracy of 91%. The Random Forest model gave us a prediction of 96% and the Gradient Boosting gave us
92%. With the computing time being the least for Random Forests and with such high accuracy, we chose Random Forests over others. 
Since this was a large dataframe, we decided to use H2O server which can handle such large dataframes. 
The right most column in the submission file determines the probability of whether the customer would be a good fit for the future.  

References: 
  https://www.kaggle.com/c/predicting-red-hat-business-value
 
https://www.rdocumentation.org/packages/h2o/versions/3.8.1.3/topics/h2o.glm
  https://cran.r-project.org/web/packages/h2o/h2o.pdf

